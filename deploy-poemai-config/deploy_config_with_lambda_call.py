import argparse
import copy
import json
import logging
import time
import uuid
from decimal import Decimal
from pathlib import Path

import boto3
import yaml

_logger = logging.getLogger(__name__)


# Object type recognition (adapted from poemai-config)
obj_type_recognition_map = {
    ("CORPUS_KEY", "ASSISTANT_ID"): "ASSISTANT",
    ("CORPUS_METADATA", "CORPUS_KEY"): "CORPUS_METADATA",
    ("CORPUS_KEY", "CASE_MANAGER_ID"): "CASE_MANAGER",
}

id_name_by_object_type = {
    "ASSISTANT": "assistant_id",
    "CORPUS_METADATA": "corpus_key",
    "CASE_MANAGER": "case_manager_id",
}


def calc_obj_type(obj):
    """Calculate object type from pk/sk keys"""
    pk = obj.get("pk", "")
    sk = obj.get("sk", "")
    return obj_type_recognition_map.get((pk.split("#")[0], sk.split("#")[0]), None)


def replace_floats_with_decimal(obj):
    """Convert floats to Decimal for DynamoDB compatibility"""
    if isinstance(obj, dict):
        return {key: replace_floats_with_decimal(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [replace_floats_with_decimal(item) for item in obj]
    elif isinstance(obj, float):
        return Decimal(str(obj))
    else:
        return obj


def replace_decimal_with_string(obj):
    """Convert Decimal back to string for JSON serialization"""
    if isinstance(obj, dict):
        return {key: replace_decimal_with_string(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [replace_decimal_with_string(item) for item in obj]
    elif isinstance(obj, Decimal):
        return str(obj)
    else:
        return obj


def transform_for_temporary_corpus_key(objects_to_load, new_corpus_key, ttl_seconds):
    """Transform objects for temporary corpus key deployment with TTL"""
    _logger.info(
        f"Transforming {len(objects_to_load)} objects for temporary corpus key: {new_corpus_key}"
    )

    # Collect all existing IDs and create mapping
    key_mapping = {}
    objects_by_id = {}

    # First pass: collect all object IDs
    for obj in objects_to_load:
        obj_type = calc_obj_type(obj)
        if obj_type and obj_type in id_name_by_object_type:
            id_name = id_name_by_object_type[obj_type]
            old_id = obj.get(id_name)
            if old_id:
                key_mapping[old_id] = uuid.uuid4().hex
                objects_by_id[old_id] = obj
                _logger.debug(f"Mapped {obj_type} ID {old_id} -> {key_mapping[old_id]}")

    # Second pass: transform all objects
    transformed_objects = []
    for obj in objects_to_load:
        obj_type = calc_obj_type(obj)
        transformed_obj = copy.deepcopy(obj)

        # Set new corpus key and TTL for all objects
        transformed_obj["corpus_key"] = new_corpus_key
        transformed_obj["ttl"] = int(ttl_seconds)

        # Remove old pk/sk - they will be regenerated by the lambda
        transformed_obj.pop("pk", None)
        transformed_obj.pop("sk", None)

        if obj_type == "CORPUS_METADATA":
            # For corpus metadata, use the new corpus key as the ID
            new_id = new_corpus_key
            transformed_obj["corpus_key"] = new_corpus_key

            # Update case manager references if they exist
            if "ui_settings" in transformed_obj:
                ui_settings = transformed_obj["ui_settings"]
                if "case_manager" in ui_settings:
                    case_manager = ui_settings["case_manager"]
                    if "case_manager_default_case_manager_id" in case_manager:
                        old_cm_id = case_manager["case_manager_default_case_manager_id"]
                        if old_cm_id in key_mapping:
                            case_manager["case_manager_default_case_manager_id"] = (
                                key_mapping[old_cm_id]
                            )
                            _logger.info(
                                f"Updated case_manager_default_case_manager_id from {old_cm_id} to {key_mapping[old_cm_id]}"
                            )

        elif obj_type in id_name_by_object_type:
            # For other object types, use the mapped ID
            id_name = id_name_by_object_type[obj_type]
            old_id = transformed_obj.get(id_name)
            if old_id in key_mapping:
                new_id = key_mapping[old_id]
                transformed_obj[id_name] = new_id
                _logger.debug(f"Updated {obj_type} {id_name} from {old_id} to {new_id}")

        # Convert floats to Decimal and back to string for JSON compatibility
        transformed_obj = replace_floats_with_decimal(transformed_obj)
        transformed_obj = replace_decimal_with_string(transformed_obj)

        transformed_objects.append(transformed_obj)
        _logger.debug(f"Transformed {obj_type} object for corpus key {new_corpus_key}")

    _logger.info(
        f"Successfully transformed {len(transformed_objects)} objects for temporary deployment"
    )
    return transformed_objects


def generate_test_bot_url(url_template, corpus_key):
    """Generate test bot URL from template and corpus key"""
    if not url_template or not corpus_key:
        return None

    # Simple Jinja2-style template substitution
    try:
        # Support both {corpus_key} and {{ corpus_key }} formats
        url = url_template.replace("{corpus_key}", corpus_key)
        url = url.replace("{{ corpus_key }}", corpus_key)
        return url
    except Exception as e:
        _logger.warning(f"Failed to generate URL from template '{url_template}': {e}")
        return None


def generate_temporary_corpus_key():
    """Generate a unique temporary corpus key"""
    return f"TEMP_{uuid.uuid4().hex[:10].upper()}"


def gather_json_representations(environment, project_root_path="."):
    """
    Gather all json representations of the configuration files
    """

    path = (
        Path(project_root_path).absolute()
        / "environments"
        / environment
        / "corpus_keys"
    )

    # traverse the directory tree and look for all yaml files

    all_objects = []
    for file in list(path.rglob("*.yaml")) + list(path.rglob("*.yml")):
        with open(file, "r") as f:
            had_error = False
            try:
                data = yaml.safe_load(f)
                all_objects.append(data)
            except yaml.composer.ComposerError as e:
                had_error = True

            if had_error:
                # try loading as multi-document yaml
                f.seek(0)
                for i, doc in enumerate(yaml.safe_load_all(f)):
                    all_objects.append(doc)
                    _logger.info(
                        f"Loaded document {i} from {file}:\n{json.dumps(doc, indent=2, ensure_ascii=False)}\n"
                    )

    _logger.info(f"Found {len(all_objects)} objects to load")
    return all_objects


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    parser = argparse.ArgumentParser(
        description="Deploy configuration with lambda call"
    )

    parser.add_argument(
        "--environment",
        required=True,
        help="Environment of the configuration (source environment to read from)",
    )

    parser.add_argument(
        "--target-environment",
        required=False,
        type=str,
        default="",
        help="Target environment to deploy to (defaults to same as source environment). Useful for cross-deployment like production config to staging.",
    )
    parser.add_argument(
        "--lambda-function-name",
        required=True,
        type=str,
        help="The name of the lambda function to call",
    )
    parser.add_argument(
        "--version-id",
        required=False,
        type=str,
        help="Optional version identifier to associate with the configuration objects.",
    )
    parser.add_argument(
        "--project-root-path",
        required=False,
        type=str,
        default=".",
        help="Path to the project root directory",
    )
    parser.add_argument(
        "--temporary-corpus-key",
        required=False,
        type=str,
        default="",
        help="Optional temporary corpus key for testing deployments with TTL. Use 'auto' to generate automatically.",
    )
    parser.add_argument(
        "--temporary-corpus-key-ttl-hours",
        required=False,
        type=int,
        default=24,
        help="TTL for temporary corpus key in hours (default: 24)",
    )
    parser.add_argument(
        "--test-bot-url-template",
        required=False,
        type=str,
        default="",
        help="Optional Jinja2 URL template for test bot (e.g., 'https://app.staging.poemai.ch/ui/town_bot/app/{corpus_key}/')",
    )
    # parse arguments
    args, unknown = parser.parse_known_args()

    # Handle temporary corpus key
    temporary_corpus_key = args.temporary_corpus_key.strip()
    if temporary_corpus_key.lower() == "auto":
        temporary_corpus_key = generate_temporary_corpus_key()
        _logger.info(
            f"Generated automatic temporary corpus key: {temporary_corpus_key}"
        )
    elif temporary_corpus_key:
        _logger.info(f"Using provided temporary corpus key: {temporary_corpus_key}")

    # Determine target environment (defaults to source environment)
    target_environment = args.target_environment.strip() or args.environment
    if target_environment != args.environment:
        _logger.info(
            f"Cross-deployment: Loading config from '{args.environment}' environment, deploying to '{target_environment}' environment"
        )
    else:
        _logger.info(
            f"Standard deployment: Using '{args.environment}' environment for both source and target"
        )

    # gather all json representations
    objects_to_load = gather_json_representations(
        args.environment, args.project_root_path
    )

    # Apply temporary corpus key transformation if specified
    if temporary_corpus_key:
        ttl_seconds = int(time.time() + (args.temporary_corpus_key_ttl_hours * 3600))
        _logger.info(
            f"Transforming objects for temporary corpus key '{temporary_corpus_key}' with TTL of {args.temporary_corpus_key_ttl_hours} hours"
        )
        objects_to_load = transform_for_temporary_corpus_key(
            objects_to_load, temporary_corpus_key, ttl_seconds
        )

        # Verify exactly one corpus key exists after transformation
        corpus_keys = set()
        for obj in objects_to_load:
            if "corpus_key" in obj:
                corpus_keys.add(obj["corpus_key"])

        if len(corpus_keys) != 1:
            _logger.error(
                f"Expected exactly one corpus key after transformation, found {len(corpus_keys)}: {corpus_keys}"
            )
            exit(1)

        _logger.info(
            f"âœ… Temporary deployment prepared with corpus key: {temporary_corpus_key} (expires in {args.temporary_corpus_key_ttl_hours} hours)"
        )

        # Generate test bot URL if template provided
        if args.test_bot_url_template:
            test_bot_url = generate_test_bot_url(
                args.test_bot_url_template, temporary_corpus_key
            )
            if test_bot_url:
                _logger.info(f"ðŸ”— Test Bot URL: {test_bot_url}")
                # Also output for GitHub Actions to pick up
                print(f"::notice title=Test Bot URL::ðŸ”— {test_bot_url}")
            else:
                _logger.warning("Failed to generate test bot URL from template")

    # Optionally add version ID to objects
    if args.version_id:
        for obj in objects_to_load:
            obj["version_id"] = args.version_id
            obj["_version_id"] = args.version_id  # add both for backwards compatibility

    # Validate pk/sk presence (skip for temporary corpus key deployments since they're removed)
    if not temporary_corpus_key:
        for i, obj in enumerate(objects_to_load):
            if "pk" not in obj:
                _logger.error(
                    f"Object {i} does not have a primary key. Object:\n{json.dumps(obj, indent=2, ensure_ascii=False)}"
                )
                exit(1)
            if "sk" not in obj:
                _logger.error(
                    f"Object {i} does not have a sort key. Object:\n{json.dumps(obj, indent=2, ensure_ascii=False)}"
                )
                exit(1)

            _logger.info(
                f"Object {i}:\n{json.dumps(obj, indent=2, ensure_ascii=False)}\n--------------------------------\n"
            )
    else:
        _logger.info(
            "Skipping pk/sk validation for temporary corpus key deployment (lambda will regenerate them)"
        )
        _logger.info(
            f"Prepared {len(objects_to_load)} objects for temporary deployment"
        )

    request = {
        "objects_to_load": objects_to_load,
        "poemai-environment": target_environment,
    }

    # Create a Lambda client
    lambda_client = boto3.client("lambda")

    try:
        response = lambda_client.invoke(
            FunctionName=args.lambda_function_name,
            InvocationType="RequestResponse",
            Payload=json.dumps(request),
        )

        # Check the status code of the response
        status_code = response.get("StatusCode")
        if status_code != 200:
            _logger.error(f"Lambda invocation failed with status code: {status_code}")
            exit(1)

        # Parse the response payload
        response_payload = response["Payload"].read()
        response_data = json.loads(response_payload)

        # Check for errors in the response
        if "errorMessage" in response_data:
            _logger.error(f"Lambda function error: {response_data['errorMessage']}")
            _logger.debug(f"Error details: {json.dumps(response_data, indent=2)}")
            exit(1)
        elif "error" in response_data:
            _logger.error(f"Lambda function error: {response_data['error']}")
            _logger.debug(f"Error details: {json.dumps(response_data, indent=2)}")
            exit(1)
        else:
            _logger.info("Lambda invocation succeeded.")
            _logger.info(
                f"Lambda response:\n{json.dumps(response_data, indent=2, ensure_ascii=False)}"
            )

    except Exception as e:
        _logger.exception(f"Failed to invoke lambda function: {e}", exc_info=e)
        exit(1)
